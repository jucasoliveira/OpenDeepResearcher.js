# Streaming Implementation

To enhance user experience, we implement **real-time streaming** of results as they are generated by the agent.

This is particularly useful for longer research queries where the user wants to see partial results as they come in.

## Fastify Streaming

In the Fastify implementation, the server sends responses in **SSE (Server-Sent Events)** format.

Hereâ€™s how it works:

1. **User sends a query**: The query is processed by the LangChain agent.
2. **Server streams results**: As the results are generated (by the `compose` tool, for example), the server sends partial responses to the client.
3. **UI Updates**: The frontend receives the streamed data and updates the UI in real-time.

## Example:

When a user requests a query like `"How does quantum computing work?"`, the response might look like this in real-time:

```plaintext
data: {"chunk": "Quantum computing leverages principles of quantum mechanics to..."}
data: {"chunk": "One of the key features of quantum computing is superposition..."}
```

This allows the user to see the article being written in real-time, without waiting for the entire response.
